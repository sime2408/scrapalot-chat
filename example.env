# Operating system application is running on
OS_RUNNING_ENVIRONMENT=windows
# Source of documents end destinatiion database ################
INGEST_PERSIST_DIRECTORY='./db/medicine'
INGEST_SOURCE_DIRECTORY='./source_documents/medicine'
INGEST_TARGET_SOURCE_CHUNKS=4
# embedding models (https://huggingface.co/spaces/mteb/leaderboard)
# (dimensions = 384) default, alternative all-MiniLM-L12-v2
INGEST_EMBEDDINGS_MODEL=all-MiniLM-L6-v2
# You can also choose a larger model don't forget to change
# HuggingFaceEmbeddings to HuggingFaceInstructEmbeddings throughout the code
# INGEST_EMBEDDINGS_MODEL=hkunlp/instructor-large
# (dimensions = 1024)
# INGEST_EMBEDDINGS_MODEL=infloat/e5-large-v2
# (dimensions = 768)
# INGEST_EMBEDDINGS_MODEL=instructor-xl
# (dimensions = 1536) - used by OpenAI
# INGEST_EMBEDDINGS_MODEL=text-embedding-ada-002
INGEST_CHUNK_SIZE=1000
INGEST_OVERLAP=100
# Commons ######################################################
MODEL_N_CTX=4096
MODEL_TEMPERATURE=0.4
MODEL_USE_MLOCK=true
MODEL_VERBOSE=false
MODEL_N_BATCH=1024
MODEL_N_THREADS=16
MODEL_TOP_P=0.9
# Translation ##################################################
TRANSLATE_QUESTION=false
TRANSLATE_ANSWER=false
TRANSLATE_DOCS=false
TRANSLATE_SRC_LANG=en
# code needs to be changed to accept other voices, for now only hr is supported
TRANSLATE_DST_LANG=hr
# Set the desired column width and the number of columns
CLI_COLUMN_WIDTH=30
CLI_COLUMN_NUMBER=4
################################################################
DB_GET_ONLY_RELEVANT_DOCS=false
# API ##########################################################
API_BASE_URL=http://127.0.0.1:8080
# gpt4all ######################################################
#MODEL_TYPE=gpt4all
#MODEL_ID_OR_PATH=models/ggml-gpt4all-j-v1.3-groovy.bin
#GPT4ALL_BACKEND=gptj
# gpt4all - llama ##############################################
#MODEL_TYPE=gpt4all
#MODEL_ID_OR_PATH=models/ggml-model-q4_0.bin
#GPT4ALL_BACKEND=llama
################################################################
MODEL_TYPE=llamacpp
MODEL_ID_OR_PATH=models/Wizard-Vicuna-7B-Uncensored.ggmlv3.q8_0.bin
#MODEL_ID_OR_PATH=models/vicuna-13b-1.1.ggmlv3.q6_K.bin
#MODEL_ID_OR_PATH=models/ggml-vic13b-q5_1.bin
#MODEL_ID_OR_PATH=models/ggml-gpt4all-l13b-snoozy.bin
#MODEL_ID_OR_PATH=models/ggml-vic13b-uncensored-q8_0.bin
#MODEL_ID_OR_PATH=models/ggml-vic13b-q5_1.bin
#MODEL_ID_OR_PATH=models/koala-7B.ggmlv3.q8_0.bin
#MODEL_ID_OR_PATH=WizardLM-7B-uncensored.ggmlv3.q8_0.bin
# GPU ##########################################################
GPU_IS_ENABLED=true
# openai #######################################################
#OPENAI_USE=true
#OPENAI_API_KEY=sk-xxx
#MODEL_TYPE=openai
# huggingface-local ############################################
#MODEL_TYPE=huggingface-local
#MODEL_ID_OR_PATH=TheBloke/guanaco-7B-HF
# hhuggingface-local ###########################################
#MODEL_TYPE=huggingface-local
#MODEL_ID_OR_PATH=h2oai/h2ogpt-gm-oasst1-multilang-2048-falcon-7b
# huggingface hub ##############################################
#MODEL_TYPE=huggingface-hub
#MODEL_ID_OR_PATH=microsoft/DialoGPT-medium
#HUGGINGFACEHUB_API_TOKEN=hf-xxx
# huggingface hub ###############################################
#MODEL_TYPE=huggingface-hub
#MODEL_ID_OR_PATH=OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5
#HUGGINGFACEHUB_API_TOKEN=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
